{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HKBU COMP7015 Aritificial Intelligence mini project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group members :  \n",
    "* 1) **Name:** <u>XU YU</u>        **Student ID:** <u>20416601</u>  **Mark:** <u>Liaison</u>\n",
    "* 2) **Name:** <u>LI WEIJIE</u>     **Student ID:** <u>20416644</u>\n",
    "* 3) **Name:** <u>LIN JUANJIA</u>    **Student ID:** <u>20430779</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import dependent package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Data Pre-progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read iris dataset as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\",header=0,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Random permutation for data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index = np.random.permutation(df.shape[0]) # random rows ,return rows index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide dataset to training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide = int(0.8* len(row_index)) # 80% as training data, 20% as test data\n",
    "training_index=row_index[:divide]\n",
    "test_index=row_index[divide:]\n",
    "\n",
    "training_set = df.loc[training_index,:]\n",
    "test_set = df.loc[test_index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_class = list(training_set.iloc[:,-1])\n",
    "test_class = list(test_set.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) KNN functions, using euclideanDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    \n",
    "    def __init__(self,TrainSet,TestData,K_value):\n",
    "        self.predictValue = self.Predict(TrainSet,TestData,K_value)\n",
    "\n",
    "    def euclideanDistance(self,point_1, point_2, data_len):\n",
    "        distance = 0\n",
    "        for i in range(data_len): # multip-attributes\n",
    "            distance = distance + np.square(point_1[i] - point_2[i])\n",
    "        return np.sqrt(distance) # root the square value.\n",
    "    \n",
    "    def Predict(self,train_dataset,test_datapoint,k):\n",
    "        distances={} # dict type key: value\n",
    "        neighbors = [] # store nearest k values, list type\n",
    "        \n",
    "        # Distance calculation \n",
    "        for x in range(len(train_dataset)):\n",
    "            dist_temp = self.euclideanDistance(test_datapoint, train_dataset.iloc[x].values, len(test_datapoint))\n",
    "            distances[x] = dist_temp\n",
    "            \n",
    "        # Ordering distances by ascending\n",
    "        sorted_distances = sorted(distances.items(),key=operator.itemgetter(1))# operator.itemgetter(1) , aim to [0]:[1] for dict type\n",
    "       \n",
    "        for x in range(k):  # range(k)\n",
    "            neighbors.append(sorted_distances[x][0]) # get the index of k-nearest points\n",
    "\n",
    "        # Voting majority in k-points\n",
    "        count_points = {\"Iris-setosa\" : 0, \"Iris-versicolor\" : 0, \"Iris-virginica\" : 0}\n",
    "        for x in range(len(neighbors)):\n",
    "            response_class = train_dataset.iloc[neighbors[x]][-1] # using index to get class label of neighbor data in training dataset\n",
    "            if response_class in count_points:\n",
    "                count_points[response_class] += 1 # count number\n",
    "            else:\n",
    "                count_points[response_class] = 1 # not in our target class\n",
    "            \n",
    "        sorted_count_points = sorted(count_points.items(), key=operator.itemgetter(1), reverse=True) # find the most frequent class(get major points during these k points)\n",
    "        \n",
    "        return sorted_count_points[0][0]  # return predict result \n",
    "    \n",
    "    def PredictResult(self):\n",
    "        return self.predictValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\n",
      "Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "testpoint = test_set.iloc[15][:4].values\n",
    "testpoint_label = test_set.iloc[15][4]\n",
    "#print(testpoint)\n",
    "print(testpoint_label)\n",
    "\n",
    "Te= KNN(training_set,testpoint,10)\n",
    "print(Te.PredictResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References  \n",
    "\n",
    "[1]Python Numpy Array Tutorial. (n.d.). Retrieved from https://www.datacamp.com/community/tutorials/python-numpy-tutorial\n",
    "\n",
    "[2]James, Gareth, Witten, Daniela, Hastie, Trevor, & Tibshirani, Robert. (2013). An introduction to statistical learning (Vol. 103, Springer texts in statistics). New York: Springer.\n",
    "\n",
    "[3]Carlsen, L., & Bruggemann, R. (2020). The iris dataset revisited – a partial ordering study. Informatica, 44(1), 35-44. doi:http://dx.doi.org.lib-ezproxy.hkbu.edu.hk/10.31449/inf.v44i1.2715\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
